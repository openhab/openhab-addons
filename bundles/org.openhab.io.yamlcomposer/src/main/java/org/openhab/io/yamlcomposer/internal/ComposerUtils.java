/*
 * Copyright (c) 2010-2026 Contributors to the openHAB project
 *
 * See the NOTICE file(s) distributed with this work for additional
 * information.
 *
 * This program and the accompanying materials are made available under the
 * terms of the Eclipse Public License 2.0 which is available at
 * http://www.eclipse.org/legal/epl-2.0
 *
 * SPDX-License-Identifier: EPL-2.0
 */
package org.openhab.io.yamlcomposer.internal;

import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Path;
import java.time.ZonedDateTime;
import java.util.ArrayList;
import java.util.IdentityHashMap;
import java.util.LinkedHashMap;
import java.util.LinkedHashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.eclipse.jdt.annotation.NonNullByDefault;
import org.eclipse.jdt.annotation.Nullable;
import org.openhab.core.OpenHAB;
import org.openhab.io.yamlcomposer.internal.constructors.ModelConstructor;
import org.snakeyaml.engine.v2.api.Dump;
import org.snakeyaml.engine.v2.api.DumpSettings;
import org.snakeyaml.engine.v2.api.Load;
import org.snakeyaml.engine.v2.api.LoadSettings;
import org.snakeyaml.engine.v2.common.FlowStyle;
import org.snakeyaml.engine.v2.resolver.ScalarResolver;
import org.snakeyaml.engine.v2.schema.CoreSchema;
import org.snakeyaml.engine.v2.schema.Schema;

/**
 * Pure utility functions for YAML preprocessing.
 *
 * @author Jimmy Tanagra - Initial contribution
 */
@NonNullByDefault
final class ComposerUtils {
    private static final String GENERATED_HEADER = """
            # ==============================================================================
            # Generated by openHAB %s (%s) YAML Composer, DO NOT EDIT
            # Source:    %s
            # Generated: %s
            # ==============================================================================
                            """;

    private ComposerUtils() {
        // Static utility class
    }

    /**
     * Removes top-level keys that start with a dot from the given map.
     *
     * @param dataMap the map to process
     */
    static void removeHiddenKeys(Map<?, ?> dataMap) {
        dataMap.keySet().removeIf(key -> key instanceof String keyStr && keyStr.startsWith("."));
    }

    /**
     * Writes the fully processed YAML representation as it would be seen by openHAB after preprocessing
     * to a compiled output file.
     *
     * @param dataMap the resulting data map to dump
     * @param sourcePath the absolute path of the source file being processed
     * @throws IOException if writing to the file fails
     */
    static void writeCompiledOutput(Object dataMap, Path sourcePath) throws IOException {

        Path outputPath = ComposerConfig.resolveOutputPath(sourcePath);

        Path outputDir = outputPath.getParent();
        if (outputDir != null) {
            Files.createDirectories(outputDir);
        }

        DumpSettings dumpSettings = DumpSettings.builder() //
                .setDefaultFlowStyle(FlowStyle.BLOCK) //
                .setIndentWithIndicator(true) //
                .setIndicatorIndent(2) //
                .setMultiLineFlow(true) //
                .build();
        Dump yaml = new Dump(dumpSettings);
        Object unaliasedData = breakAliases(dataMap);
        String compiledYaml = yaml.dumpToString(unaliasedData);
        compiledYaml = formatYamlSpacing(compiledYaml);

        Path sourcePathRelative = ComposerConfig.configRoot().relativize(sourcePath);
        compiledYaml = GENERATED_HEADER.formatted(OpenHAB.getVersion(), OpenHAB.buildString(), sourcePathRelative,
                ZonedDateTime.now()) + "\n" + compiledYaml;

        Files.writeString(outputPath, compiledYaml, StandardCharsets.UTF_8);
    }

    /**
     * Creates a new SnakeYAML Engine load instance with the custom composer constructor and resolver.
     *
     * @param sourcePath the source path of the YAML file for error reporting in the constructor
     * @return a new Load instance
     */
    static Load createYamlLoader(String sourcePath) {
        Schema schema = new CoreSchema() {
            @Override
            public ScalarResolver getScalarResolver() {
                return new ModelResolver();
            }
        };

        LoadSettings loadSettings = LoadSettings.builder() //
                .setLabel(sourcePath) //
                .setAllowDuplicateKeys(false) //
                .setUseMarks(true) //
                .setSchema(schema) //
                .build();
        return new Load(loadSettings, new ModelConstructor(loadSettings, sourcePath));
    }

    /**
     * Loads YAML content from the given byte array using a Yaml instance configured with the custom constructor.
     *
     * @param fileBytes the YAML content as a byte array
     * @param sourcePath the source path of the YAML file for error reporting in the constructor
     * @return the loaded YAML object
     * @throws IOException if an I/O error occurs
     */
    static @Nullable Object loadYaml(byte[] fileBytes, Path sourcePath) throws IOException {
        Load loader = createYamlLoader(sourcePath.toString());
        return loader.loadFromInputStream(new ByteArrayInputStream(fileBytes));
    }

    /**
     * Produces a deep-copy of the common YAML structure objects (maps, lists, sets)
     * such that no container instance is shared more than once in the resulting
     * graph. This removes object identity sharing that SnakeYAML would otherwise
     * emit as anchors/aliases when dumping.
     *
     * @param root the loaded YAML object (may be Map, List, Set, scalar, or custom)
     * @return a deep-copied object graph with sharing broken
     */
    private static @Nullable Object breakAliases(@Nullable Object root) {
        if (root == null) {
            return null;
        }
        return cloneNode(root, new IdentityHashMap<>());
    }

    /**
     * Post-processes a YAML string to inject empty lines for improved readability.
     * *
     * <p>
     * This method applies two specific spacing rules:
     * <ul>
     * <li><strong>Level 0:</strong> Inserts a newline before every top-level key (except the first line).</li>
     * <li><strong>Level 2:</strong> Inserts a newline between sibling nodes indented by exactly two spaces.</li>
     * </ul>
     * *
     * <p>
     * The logic ensures that the first child of a section remains "glued" to its parent header,
     * and it safely handles both Map keys (e.g., {@code   Key:}) and List items (e.g., {@code   - Item}).
     *
     * @param yaml The raw YAML string to be formatted.
     * @return A formatted YAML string with injected "breathing room."
     */
    public static @Nullable String formatYamlSpacing(@Nullable String yaml) {
        if (yaml == null || yaml.isEmpty()) {
            return yaml;
        }

        String[] lines = yaml.split("\n");
        StringBuilder sb = new StringBuilder();

        boolean hasSeenLevel0 = false;
        boolean hasSeenLevel2 = false;

        for (String line : lines) {
            // --- Level 0 Logic (Sections) ---
            // Matches lines starting with a character (not space, not comment)
            if (!line.startsWith(" ") && !line.startsWith("#")) {
                if (hasSeenLevel0) {
                    sb.append("\n");
                }
                hasSeenLevel0 = true;
                hasSeenLevel2 = false; // Reset level 2 tracker for the new section
            }

            // --- Level 2 Logic (Items or List Elements) ---
            // Matches exactly 2 spaces followed by a non-whitespace character.
            // This targets siblings within a top-level section.
            else if (line.matches("^ {2}[^ \\t].*")) {
                if (hasSeenLevel2) {
                    sb.append("\n");
                }
                hasSeenLevel2 = true;
            }

            sb.append(line).append("\n");
        }

        return sb.toString().trim();
    }

    private static @Nullable Object cloneNode(@Nullable Object node, IdentityHashMap<Object, Object> stack) {
        if (node == null) {
            return null;
        }
        // Scalars and non-container objects are returned as-is
        if (!(node instanceof Map) && !(node instanceof List) && !(node instanceof Set)) {
            return node;
        }

        // If the node is already on the current recursion stack, return the
        // partially-built copy to handle cycles. We do NOT reuse completed
        // copies for separate occurrences â€” that would preserve sharing and
        // produce aliases.
        if (stack.containsKey(node)) {
            return stack.get(node);
        }

        if (node instanceof Map) {
            @SuppressWarnings("unchecked")
            Map<@Nullable Object, @Nullable Object> original = (Map<@Nullable Object, @Nullable Object>) node;
            Map<@Nullable Object, @Nullable Object> copy = new LinkedHashMap<>(original.size());
            stack.put(node, copy);
            for (Map.Entry<@Nullable Object, @Nullable Object> e : original.entrySet()) {
                Object k = e.getKey();
                Object v = e.getValue();
                Object newKey = cloneNode(k, stack);
                Object newVal = cloneNode(v, stack);
                copy.put(newKey, newVal);
            }
            // Remove from stack so later separate occurrences are cloned again
            stack.remove(node);
            return copy;
        }

        if (node instanceof List) {
            @SuppressWarnings("unchecked")
            List<@Nullable Object> original = (List<@Nullable Object>) node;
            List<@Nullable Object> copy = new ArrayList<>(original.size());
            stack.put(node, copy);
            for (@Nullable
            Object item : original) {
                copy.add(cloneNode(item, stack));
            }
            stack.remove(node);
            return copy;
        }

        // Set (preserve insertion order if possible)
        if (node instanceof Set) {
            @SuppressWarnings("unchecked")
            Set<@Nullable Object> original = (Set<@Nullable Object>) node;
            Set<@Nullable Object> copy = new LinkedHashSet<>(original.size());
            stack.put(node, copy);
            for (Object item : original) {
                copy.add(cloneNode(item, stack));
            }
            stack.remove(node);
            return copy;
        }

        // Fallback: return node as-is
        return node;
    }
}
